{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cda7513-db89-47ba-a348-a9af842097a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3cda7513-db89-47ba-a348-a9af842097a1",
    "outputId": "88763a28-bb53-4b4b-8fdd-67c99964a14a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: nltk in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /home/itbecomesteam/.local/lib/python3.12/site-packages (from nltk) (4.67.1)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/itbecomesteam/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3094142e-655d-43d6-84ee-488b12ec6658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in /home/itbecomesteam/.local/lib/python3.12/site-packages (4.38.2)\n",
      "Requirement already satisfied: filelock in /home/itbecomesteam/.local/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from transformers) (0.32.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /home/itbecomesteam/.local/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (1.1.2)\n",
      "INFO: pip is looking at multiple versions of tokenizers to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
      "  Using cached tokenizers-0.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from requests->transformers) (2025.4.26)\n",
      "Using cached tokenizers-0.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: tokenizers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.14.1\n",
      "    Uninstalling tokenizers-0.14.1:\n",
      "      Successfully uninstalled tokenizers-0.14.1\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed tokenizers-0.15.2\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: accelerate in /home/itbecomesteam/.local/lib/python3.12/site-packages (0.26.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in /home/itbecomesteam/.local/lib/python3.12/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /home/itbecomesteam/.local/lib/python3.12/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from accelerate) (2.5.1+cu121)\n",
      "Requirement already satisfied: huggingface-hub in /home/itbecomesteam/.local/lib/python3.12/site-packages (from accelerate) (0.32.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (4.13.2)\n",
      "Requirement already satisfied: networkx in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (80.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.6.85)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: requests in /home/itbecomesteam/.local/lib/python3.12/site-packages (from huggingface-hub->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from huggingface-hub->accelerate) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from huggingface-hub->accelerate) (1.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from requests->huggingface-hub->accelerate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from requests->huggingface-hub->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from requests->huggingface-hub->accelerate) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from requests->huggingface-hub->accelerate) (2025.4.26)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: hf_xet in /home/itbecomesteam/.local/lib/python3.12/site-packages (1.1.2)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: datasets in /home/itbecomesteam/.local/lib/python3.12/site-packages (3.6.0)\n",
      "Requirement already satisfied: filelock in /home/itbecomesteam/.local/lib/python3.12/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/itbecomesteam/.local/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from datasets) (0.32.0)\n",
      "Requirement already satisfied: packaging in /home/itbecomesteam/.local/lib/python3.12/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: bert-score in /home/itbecomesteam/.local/lib/python3.12/site-packages (0.3.13)\n",
      "Requirement already satisfied: torch>=1.0.0 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from bert-score) (2.5.1+cu121)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from bert-score) (2.2.2)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from bert-score) (4.38.2)\n",
      "Requirement already satisfied: numpy in /home/itbecomesteam/.local/lib/python3.12/site-packages (from bert-score) (1.26.4)\n",
      "Requirement already satisfied: requests in /home/itbecomesteam/.local/lib/python3.12/site-packages (from bert-score) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from bert-score) (4.67.1)\n",
      "Requirement already satisfied: matplotlib in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from bert-score) (3.9.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from bert-score) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from pandas>=1.0.1->bert-score) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from pandas>=1.0.1->bert-score) (2023.3)\n",
      "Requirement already satisfied: filelock in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (4.13.2)\n",
      "Requirement already satisfied: networkx in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (80.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0.0->bert-score) (12.6.85)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (0.32.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (0.5.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from matplotlib->bert-score) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from matplotlib->bert-score) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from matplotlib->bert-score) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from matplotlib->bert-score) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from matplotlib->bert-score) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from matplotlib->bert-score) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from requests->bert-score) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from requests->bert-score) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from requests->bert-score) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from requests->bert-score) (2025.4.26)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers>=3.0.0->bert-score) (1.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: blobfile in /home/itbecomesteam/.local/lib/python3.12/site-packages (3.0.0)\n",
      "Requirement already satisfied: tiktoken in /home/itbecomesteam/.local/lib/python3.12/site-packages (0.9.0)\n",
      "Requirement already satisfied: pycryptodomex>=3.8 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from blobfile) (3.23.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.25.3 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from blobfile) (2.4.0)\n",
      "Requirement already satisfied: lxml>=4.9 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from blobfile) (5.2.1)\n",
      "Requirement already satisfied: filelock>=3.0 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from blobfile) (3.18.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from tiktoken) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Collecting torch==2.3.1\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torch-2.3.1%2Bcu121-cp312-cp312-linux_x86_64.whl (780.9 MB)\n",
      "Requirement already satisfied: filelock in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch==2.3.1) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch==2.3.1) (4.13.2)\n",
      "Requirement already satisfied: sympy in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch==2.3.1) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch==2.3.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch==2.3.1) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch==2.3.1) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch==2.3.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch==2.3.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch==2.3.1) (12.1.105)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.1)\n",
      "  Using cached https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch==2.3.1) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch==2.3.1) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch==2.3.1) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch==2.3.1) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch==2.3.1) (12.1.0.106)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.1)\n",
      "  Using cached https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch==2.3.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1) (12.6.85)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from jinja2->torch==2.3.1) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from sympy->torch==2.3.1) (1.3.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: nvidia-nccl-cu12, nvidia-cudnn-cu12, torch\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
      "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
      "  Attempting uninstall: torch\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: torch 2.5.1+cu121\n",
      "    Uninstalling torch-2.5.1+cu121:\n",
      "      Successfully uninstalled torch-2.5.1+cu121\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.17.2+cu118 requires torch==2.2.2, but you have torch 2.3.1+cu121 which is incompatible.\n",
      "torchaudio 2.2.2+cu118 requires torch==2.2.2, but you have torch 2.3.1+cu121 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cudnn-cu12-8.9.2.26 nvidia-nccl-cu12-2.20.5 torch-2.3.1+cu121\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: datasets==3.6.0 in /home/itbecomesteam/.local/lib/python3.12/site-packages (3.6.0)\n",
      "Requirement already satisfied: filelock in /home/itbecomesteam/.local/lib/python3.12/site-packages (from datasets==3.6.0) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from datasets==3.6.0) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from datasets==3.6.0) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from datasets==3.6.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from datasets==3.6.0) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from datasets==3.6.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from datasets==3.6.0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/itbecomesteam/.local/lib/python3.12/site-packages (from datasets==3.6.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from datasets==3.6.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from datasets==3.6.0) (0.32.0)\n",
      "Requirement already satisfied: packaging in /home/itbecomesteam/.local/lib/python3.12/site-packages (from datasets==3.6.0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from datasets==3.6.0) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (3.10.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets==3.6.0) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from requests>=2.32.2->datasets==3.6.0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from requests>=2.32.2->datasets==3.6.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from requests>=2.32.2->datasets==3.6.0) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from requests>=2.32.2->datasets==3.6.0) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from pandas->datasets==3.6.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from pandas->datasets==3.6.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from pandas->datasets==3.6.0) (2023.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/itbecomesteam/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets==3.6.0) (1.16.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting tokenizers==0.14.1\n",
      "  Using cached tokenizers-0.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting huggingface_hub<0.18,>=0.16.4 (from tokenizers==0.14.1)\n",
      "  Using cached huggingface_hub-0.17.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /home/itbecomesteam/.local/lib/python3.12/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers==0.14.1) (3.18.0)\n",
      "Requirement already satisfied: fsspec in /home/itbecomesteam/.local/lib/python3.12/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers==0.14.1) (2025.3.0)\n",
      "Requirement already satisfied: requests in /home/itbecomesteam/.local/lib/python3.12/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers==0.14.1) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers==0.14.1) (4.67.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers==0.14.1) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers==0.14.1) (4.13.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers==0.14.1) (25.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from requests->huggingface_hub<0.18,>=0.16.4->tokenizers==0.14.1) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from requests->huggingface_hub<0.18,>=0.16.4->tokenizers==0.14.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from requests->huggingface_hub<0.18,>=0.16.4->tokenizers==0.14.1) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from requests->huggingface_hub<0.18,>=0.16.4->tokenizers==0.14.1) (2025.4.26)\n",
      "Using cached tokenizers-0.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "Using cached huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: huggingface_hub, tokenizers\n",
      "  Attempting uninstall: huggingface_hub\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: huggingface-hub 0.32.0\n",
      "    Uninstalling huggingface-hub-0.32.0:\n",
      "      Successfully uninstalled huggingface-hub-0.32.0\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.15.2\n",
      "    Uninstalling tokenizers-0.15.2:\n",
      "      Successfully uninstalled tokenizers-0.15.2\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.6.0 requires huggingface-hub>=0.24.0, but you have huggingface-hub 0.17.3 which is incompatible.\n",
      "transformers 4.38.2 requires huggingface-hub<1.0,>=0.19.3, but you have huggingface-hub 0.17.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed huggingface_hub-0.17.3 tokenizers-0.14.1\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting huggingface_hub==0.32.0\n",
      "  Using cached huggingface_hub-0.32.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: filelock in /home/itbecomesteam/.local/lib/python3.12/site-packages (from huggingface_hub==0.32.0) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from huggingface_hub==0.32.0) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from huggingface_hub==0.32.0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from huggingface_hub==0.32.0) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/itbecomesteam/.local/lib/python3.12/site-packages (from huggingface_hub==0.32.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from huggingface_hub==0.32.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from huggingface_hub==0.32.0) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from huggingface_hub==0.32.0) (1.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from requests->huggingface_hub==0.32.0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from requests->huggingface_hub==0.32.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from requests->huggingface_hub==0.32.0) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from requests->huggingface_hub==0.32.0) (2025.4.26)\n",
      "Using cached huggingface_hub-0.32.0-py3-none-any.whl (509 kB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: huggingface_hub\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 0.17.3\n",
      "    Uninstalling huggingface-hub-0.17.3:\n",
      "      Successfully uninstalled huggingface-hub-0.17.3\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tokenizers 0.14.1 requires huggingface_hub<0.18,>=0.16.4, but you have huggingface-hub 0.32.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed huggingface_hub-0.32.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: sentencepiece in /home/itbecomesteam/.local/lib/python3.12/site-packages (0.2.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install accelerate\n",
    "!pip install hf_xet\n",
    "!pip install datasets\n",
    "!pip install bert-score\n",
    "!pip install blobfile tiktoken\n",
    "!pip install torch==2.3.1 --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install datasets==3.6.0\n",
    "!pip install tokenizers==0.14.1 \n",
    "!pip install huggingface_hub==0.32.0\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e406c32-b357-4022-88b4-130a9407b1bd",
   "metadata": {
    "id": "1e406c32-b357-4022-88b4-130a9407b1bd"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(\"/root/.cache/huggingface/metrics\", ignore_errors=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ece5e40-379f-4485-89e7-d25635c6c747",
   "metadata": {
    "id": "5ece5e40-379f-4485-89e7-d25635c6c747"
   },
   "source": [
    "  \n",
    "T5  mT5   Transformer decoder  use_cache=True  \n",
    "   decoder_input_ids shift   , labels alignment .\n",
    "  .\n",
    " T5-like models must have use_cache=False during training, or loss will not be computed correctly\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.decoder_start_token_id = tokenizer.eos_token_id\n",
    " !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fdfe100-91b5-4b5b-a2f8-718605488ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in /home/itbecomesteam/.local/lib/python3.12/site-packages (2.3.1+cu121)\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp312-cp312-linux_x86_64.whl (780.4 MB)\n",
      "Requirement already satisfied: filelock in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch) (12.1.0.106)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch) (80.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/itbecomesteam/.local/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: nvidia-nccl-cu12, nvidia-cudnn-cu12, torch\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: nvidia-nccl-cu12 2.20.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.20.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.20.5\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 8.9.2.26\n",
      "    Uninstalling nvidia-cudnn-cu12-8.9.2.26:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-8.9.2.26\n",
      "  Attempting uninstall: torch\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: torch 2.3.1+cu121\n",
      "    Uninstalling torch-2.3.1+cu121:\n",
      "      Successfully uninstalled torch-2.3.1+cu121\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.17.2+cu118 requires torch==2.2.2, but you have torch 2.5.1+cu121 which is incompatible.\n",
      "torchaudio 2.2.2+cu118 requires torch==2.2.2, but you have torch 2.5.1+cu121 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cudnn-cu12-9.1.0.70 nvidia-nccl-cu12-2.21.5 torch-2.5.1+cu121\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/itbecomesteam/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade torch --index-url https://download.pytorch.org/whl/cu121\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38be497c-2986-4875-990b-4b0f4834aeaa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "3db0691c2149494a954b4ed993fc9707",
      "c15f82108f424c15a5841b9255a623f0",
      "fe638bb582bc4fbf8c36e2deff1a4e2d",
      "b1dea5ee24944a9aa4dbd0cd7f39008b",
      "f7c24c3d6b4644f8ad3d103dd9c75ce1",
      "214f7b7c45e84dc8916f31988e1039eb",
      "71be0ce8f4c641378c799fc231abe6dd",
      "0a73f471607d4cc8b66a14914c7ebb34",
      "2370eb6bdaf646589f09aa75d1bf58ec",
      "908b8c7f74a34fb598a85ddb26f6e98c",
      "608b9c94c523414782b09b5284aef51f",
      "51e221d6cecd49e1bf744269f05ec430",
      "86df0975f00648819dde178a1864bcd6",
      "42683c31707c4b5a9bb8aae95870881f",
      "d497d8842a6040ed9d57f29465afad9a",
      "e78bd0649de24106b06ff37f04942c0f",
      "56fffba355ab4331b62e1af32b65db2b",
      "10046844076b4923856f236029564a89",
      "289192d1a6cd45b5a13c374ddd87984b",
      "7d23c5b6a3024ffcb2197740bdedb1a8",
      "85912ace6ed1420397426adf5f44cf7b",
      "69b3e7d7fd3649b4986917204fb38ce3"
     ]
    },
    "id": "38be497c-2986-4875-990b-4b0f4834aeaa",
    "outputId": "a3500f07-cf97-45a7-cb47-d75982476c42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [Hardware Info]\n",
      "CUDA Available: True\n",
      "Device Name: NVIDIA RTX A6000\n",
      "Memory Allocated (MB): 2227.1845703125\n",
      "Memory Cached (MB): 2290.0\n",
      "Total Memory (MB): 48550.4375\n",
      "CPU Cores: 20\n",
      "Logical CPUs: 40\n",
      "Total RAM (GB): 188.54\n",
      "Cleaning GPU Cache...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca66e69d41134af3aa230e6645c77f39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/85593 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "583ad6583c054f4bb3f334d8e04d3d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21399 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    ")\n",
    "from evaluate import load\n",
    "from nltk.tokenize import word_tokenize\n",
    "import editdistance\n",
    "import torch.nn.functional as F\n",
    "import psutil\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:32\"\n",
    "\n",
    "#       \n",
    "def show_hardware_status():\n",
    "    print(\"\\n[Hardware Info]\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "        print(\"Device Name:\", torch.cuda.get_device_name(0))\n",
    "        print(\"Memory Allocated (MB):\", torch.cuda.memory_allocated(0) / 1024 ** 2)\n",
    "        print(\"Memory Cached (MB):\", torch.cuda.memory_reserved(0) / 1024 ** 2)\n",
    "        print(\"Total Memory (MB):\", torch.cuda.get_device_properties(0).total_memory / 1024 ** 2)\n",
    "    else:\n",
    "        print(\"CUDA not available. Using CPU.\")\n",
    "    print(\"CPU Cores:\", psutil.cpu_count(logical=False))\n",
    "    print(\"Logical CPUs:\", psutil.cpu_count(logical=True))\n",
    "    print(\"Total RAM (GB):\", round(psutil.virtual_memory().total / 1024**3, 2))\n",
    "    print(\"Cleaning GPU Cache...\\n\")\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "show_hardware_status()\n",
    "\n",
    "# Model/tokenizer load (base or small)\n",
    "model_name = \"google/mt5-small\"  # mT5-small/mt5-base\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# T5     \n",
    "model.config.use_cache = False\n",
    "model.config.decoder_start_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Full-data loading\n",
    "\n",
    "raw_df = pd.read_csv(\"/home/itbecomesteam/yai/Data_filtered.csv\", encoding=\"utf-8\")\n",
    "# raw_df = raw_df[[\"source\", \"ko\"]].rename(columns={\"source\": \"input_text\", \"ko\": \"target_text\"})\n",
    "raw_df = raw_df[[\"ko_translationese\", \"ko\"]].rename(columns={\"ko_translationese\": \"input_text\", \"ko\": \"target_text\"})\n",
    "raw_df = raw_df.dropna()\n",
    "raw_df[\"input_text\"] = raw_df[\"input_text\"].astype(str)\n",
    "raw_df[\"target_text\"] = raw_df[\"target_text\"].astype(str)\n",
    "\n",
    "raw_df = raw_df[~raw_df[\"input_text\"].str.strip().eq(\"\")]\n",
    "raw_df = raw_df[~raw_df[\"target_text\"].str.strip().eq(\"\")]\n",
    "\n",
    "raw_dataset = Dataset.from_pandas(raw_df)\n",
    "dataset_split = raw_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "full_ds = DatasetDict({\n",
    "    \"train\": dataset_split[\"train\"],\n",
    "    \"validation\": dataset_split[\"test\"]\n",
    "})\n",
    "\n",
    "# Preprocessing\n",
    "def preprocess(example):\n",
    "    model_inputs = tokenizer(\n",
    "        example[\"input_text\"], max_length=128, padding=\"max_length\", truncation=True\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        text_target=example[\"target_text\"], max_length=128, padding=\"max_length\", truncation=True\n",
    "    )[\"input_ids\"]\n",
    "    labels = [label if label != tokenizer.pad_token_id else -100 for label in labels]\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs\n",
    "\n",
    "full_tokenized = full_ds.map(preprocess, remove_columns=full_ds[\"train\"].column_names)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding=True)\n",
    "\n",
    "# 4.  perplexity   (  )\n",
    "val_loader = DataLoader(\n",
    "    full_tokenized[\"validation\"],\n",
    "    batch_size=8,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def compute_perplexity_from_preds(preds, refs):\n",
    "    total_logp = 0.0\n",
    "    total_tokens = 0\n",
    "\n",
    "    for pred_text, ref_text in zip(preds, refs):\n",
    "        input_ids = tokenizer(pred_text, return_tensors=\"pt\", padding=True, truncation=True).input_ids.to(model.device)\n",
    "        labels = tokenizer(ref_text, return_tensors=\"pt\", padding=True, truncation=True).input_ids.to(model.device)\n",
    "        with torch.no_grad():\n",
    "            output = model(input_ids=input_ids, labels=labels)\n",
    "        loss = output.loss\n",
    "        n_tokens = (labels != -100).sum().item()\n",
    "        total_logp += loss.item() * n_tokens\n",
    "        total_tokens += n_tokens\n",
    "\n",
    "    return math.exp(total_logp / total_tokens) if total_tokens > 0 else float(\"inf\")\n",
    "\n",
    "\n",
    "# Matric\n",
    "def compute_metrics(eval_preds):\n",
    "    pred_ids = eval_preds.predictions\n",
    "    label_ids = eval_preds.label_ids\n",
    "\n",
    "    # padding  \n",
    "    pred_ids = np.where(pred_ids != -100, pred_ids, tokenizer.pad_token_id)\n",
    "    label_ids = np.where(label_ids != -100, label_ids, tokenizer.pad_token_id)\n",
    "\n",
    "    # \n",
    "    preds = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    refs = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    preds = [p.strip() for p in preds]\n",
    "    refs = [r.strip() for r in refs]\n",
    "\n",
    "    preds_nonempty = [p for p in preds if p]\n",
    "    refs_nonempty = [r for r in refs if r]\n",
    "\n",
    "    if not preds_nonempty or not refs_nonempty:\n",
    "        return {\n",
    "            \"MATTR\": 0.0,\n",
    "            \"KoBERTScore_F1\": 0.0,\n",
    "            \"Perplexity\": float(\"inf\"),\n",
    "            \"Levenshtein_Distance\": float(\"inf\")\n",
    "        }\n",
    "\n",
    "    # MATTR\n",
    "    def mattr(texts, window_size=50):\n",
    "        def single(text):\n",
    "            tokens = text.split()\n",
    "            if len(tokens) < window_size:\n",
    "                return len(set(tokens)) / len(tokens) if tokens else 0.0\n",
    "            return np.mean([\n",
    "                len(set(tokens[i:i+window_size])) / window_size\n",
    "                for i in range(len(tokens) - window_size + 1)\n",
    "            ])\n",
    "        return np.mean([single(t) for t in texts])\n",
    "\n",
    "    mattr_score = mattr(preds_nonempty)\n",
    "\n",
    "    # BERTScore (KoBERT)\n",
    "    bs_metric = load(\"bertscore\", keep_in_memory=True)\n",
    "    bs_results = bs_metric.compute(predictions=preds_nonempty, references=refs_nonempty, lang=\"ko\")\n",
    "    f1_kobert = float(np.mean(bs_results[\"f1\"]))\n",
    "\n",
    "    # Levenshtein Distance\n",
    "    import editdistance\n",
    "    ld = np.mean([editdistance.eval(p, r) for p, r in zip(preds_nonempty, refs_nonempty)])\n",
    "\n",
    "    # PPL: preds + refs \n",
    "    def compute_perplexity_from_preds(preds, refs):\n",
    "        model.eval()\n",
    "        total_logp = 0.0\n",
    "        total_tokens = 0\n",
    "\n",
    "        for pred_text, ref_text in zip(preds, refs):\n",
    "            input_ids = tokenizer(pred_text, return_tensors=\"pt\", padding=True, truncation=True).input_ids.to(model.device)\n",
    "            labels = tokenizer(ref_text, return_tensors=\"pt\", padding=True, truncation=True).input_ids.to(model.device)\n",
    "            labels[labels == tokenizer.pad_token_id] = -100\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids=input_ids, labels=labels)\n",
    "                loss = outputs.loss\n",
    "            n_tokens = (labels != -100).sum().item()\n",
    "            total_logp += loss.item() * n_tokens\n",
    "            total_tokens += n_tokens\n",
    "\n",
    "        return math.exp(total_logp / total_tokens) if total_tokens > 0 else float(\"inf\")\n",
    "\n",
    "    ppl = compute_perplexity_from_preds(preds_nonempty, refs_nonempty)\n",
    "\n",
    "    return {\n",
    "        \"MATTR\": round(mattr_score, 4),\n",
    "        \"KoBERTScore_F1\": round(f1_kobert, 4),\n",
    "        \"Perplexity\": round(ppl, 4),\n",
    "        \"Levenshtein_Distance\": round(ld, 2),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8330bb23-e033-4fc8-a13b-682bab7bb9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/itbecomesteam/.local/lib/python3.12/site-packages/accelerate/accelerator.py:449: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=-100 \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"output/mt5_small-translationese-mitigation\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=64,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    fp16=True,  #  fp16=True  \n",
    "    report_to=[\"wandb\", \"tensorboard\"]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=full_tokenized[\"train\"],\n",
    "    eval_dataset=full_tokenized[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90087d18-d05b-4914-a903-bcd3947f2c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)  #   2.2  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2400d821-e09b-41bf-bf34-bdbc42654b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcosmic4dev\u001b[0m (\u001b[33mcosmic4dev-yonsei-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/itbecomesteam/yai/\bkw/wandb/run-20250601_203335-4t6znvnh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cosmic4dev-yonsei-university/huggingface/runs/4t6znvnh' target=\"_blank\">lilac-frost-71</a></strong> to <a href='https://wandb.ai/cosmic4dev-yonsei-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cosmic4dev-yonsei-university/huggingface' target=\"_blank\">https://wandb.ai/cosmic4dev-yonsei-university/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cosmic4dev-yonsei-university/huggingface/runs/4t6znvnh' target=\"_blank\">https://wandb.ai/cosmic4dev-yonsei-university/huggingface/runs/4t6znvnh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/itbecomesteam/.local/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13375' max='13375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13375/13375 5:15:10, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mattr</th>\n",
       "      <th>Kobertscore F1</th>\n",
       "      <th>Perplexity</th>\n",
       "      <th>Levenshtein Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.608600</td>\n",
       "      <td>2.058083</td>\n",
       "      <td>0.992200</td>\n",
       "      <td>0.853800</td>\n",
       "      <td>9.215000</td>\n",
       "      <td>15.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.336800</td>\n",
       "      <td>1.941612</td>\n",
       "      <td>0.993500</td>\n",
       "      <td>0.856700</td>\n",
       "      <td>7.968300</td>\n",
       "      <td>15.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.247700</td>\n",
       "      <td>1.874399</td>\n",
       "      <td>0.993900</td>\n",
       "      <td>0.858000</td>\n",
       "      <td>7.392200</td>\n",
       "      <td>15.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.193000</td>\n",
       "      <td>1.846628</td>\n",
       "      <td>0.993500</td>\n",
       "      <td>0.858700</td>\n",
       "      <td>7.138100</td>\n",
       "      <td>15.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.214000</td>\n",
       "      <td>1.839588</td>\n",
       "      <td>0.993600</td>\n",
       "      <td>0.858800</td>\n",
       "      <td>7.098200</td>\n",
       "      <td>15.030000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/itbecomesteam/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Checkpoint destination directory output/mt5_small-translationese-mitigation/checkpoint-2675 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/home/itbecomesteam/.local/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/itbecomesteam/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/itbecomesteam/.local/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/itbecomesteam/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/itbecomesteam/.local/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/itbecomesteam/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/itbecomesteam/.local/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/itbecomesteam/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=13375, training_loss=2.6290146393107476, metrics={'train_runtime': 18914.4208, 'train_samples_per_second': 22.626, 'train_steps_per_second': 0.707, 'total_flos': 5.65715903643648e+16, 'train_loss': 2.6290146393107476, 'epoch': 5.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc931625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best checkpoint path: output/mt5_small-translationese-mitigation/checkpoint-13375\n"
     ]
    }
   ],
   "source": [
    "best_ckpt = trainer.state.best_model_checkpoint\n",
    "print(\"Best checkpoint path:\", best_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0940d274-a436-4459-8916-8eb7e0be74d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              input_text  \\\n",
      "14653                     .   \n",
      "74244                      .   \n",
      "70677                             .   \n",
      "5693                              !   \n",
      "94545  \"   ,      \" ...   \n",
      "\n",
      "                                            target_text  \n",
      "14653               .  \n",
      "74244                        .  \n",
      "70677                              .  \n",
      "5693                               !  \n",
      "94545  \"  ,    \"  .  \n"
     ]
    }
   ],
   "source": [
    "print(raw_df.sample(5))  # input_text target_text      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eb7d42-67c8-4a4f-8d73-419957d5ae9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " : UV    . 400mm     100% .    .\n",
      " : UV   400mm     100% .\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_path = \"output/mt5_small-translationese-mitigation/checkpoint-13375\"  \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path).to(\"cuda\")\n",
    "\n",
    "#  \n",
    "input_text = \"UV    . 400mm     100% .    .\"\n",
    "\n",
    "# \n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=128).to(\"cuda\")\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs,decoder_start_token_id=tokenizer.eos_token_id, max_new_tokens=256, num_beams=5)\n",
    "result = tokenizer.decode(outputs[0], skip_special_tokens=True).replace(\"<extra_id_0>\", \"\").strip()\n",
    "\n",
    "\n",
    "print(\" :\", input_text)\n",
    "print(\" :\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "88ca57c6-b54d-470d-b9ab-6a751c1bcce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1:  10  .\n",
      " 1:  10  .\n",
      "\n",
      " 2:     .\n",
      " 2:     .\n",
      "\n",
      " 3:            .\n",
      " 3:            .\n",
      "\n",
      " 4:    .\n",
      " 4:     .\n",
      "\n",
      " 5:      .\n",
      " 5:     .\n",
      "\n",
      " 6:       .\n",
      " 6:       .\n",
      "\n",
      " 7:     .\n",
      " 7:     .\n",
      "\n",
      " 8:       .\n",
      " 8:       .\n",
      "\n",
      " 9:            .\n",
      " 9:            .\n",
      "\n",
      " 10:    2           .\n",
      " 10:    2           .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "#  \n",
    "model_dir = \"output/mt5_small-translationese-mitigation/checkpoint-13375\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_dir).to(\"cuda\")\n",
    "model.eval()\n",
    "\n",
    "#   \n",
    "# translationese_list = [\n",
    "#     \"    .\",\n",
    "#     \"   ,  .\",\n",
    "#     \"      .\",\n",
    "#     \"   .\",\n",
    "#     \"     .\",\n",
    "#     \"      .\",\n",
    "#     \"   .\",\n",
    "#     \"      .\",\n",
    "#     \"    .\",\n",
    "#     \"     .\"\n",
    "# ]\n",
    "# translationese_list = [\n",
    "#     \"      .\",\n",
    "#     \"       .\",\n",
    "#     \"      .\",\n",
    "#     \"     .\",\n",
    "#     \"     .\",\n",
    "#     \"    .\",\n",
    "#     \"     .\",\n",
    "#     \"    .\",\n",
    "#     \"        .\",\n",
    "#     \"      .\",\n",
    "#     \"   .\",\n",
    "#     \"      .\",\n",
    "#     \"    .\",\n",
    "#     \"     .\",\n",
    "#     \"      .\"\n",
    "# ]\n",
    "# translationese_list = [\n",
    "#     \"     .\",\n",
    "#     \"     .\",\n",
    "#     \"      .\",\n",
    "#     \"     .\",\n",
    "#     \"     .\",\n",
    "#     \"    .\",\n",
    "#     \"     .\",\n",
    "#     \"      .\",\n",
    "#     \"    .\",\n",
    "#     \"      .\"\n",
    "# ]\n",
    "\n",
    "#   input\n",
    "translationese_list = [\n",
    "           ' 10  .',\n",
    "           '    .', #   .\n",
    "           '           .', # ,      .\n",
    "           '   .', #   .\n",
    "           '     .', #    .\n",
    "           '      .', #      .\n",
    "           '    .', #     .\n",
    "           '      .', #    . \n",
    "           '           .', #               .\n",
    "           '   2           .' #    2            .\n",
    "\n",
    "]\n",
    "\n",
    "#   \n",
    "for idx, sentence in enumerate(translationese_list, 1):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=128).to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            decoder_start_token_id=tokenizer.eos_token_id,\n",
    "            max_new_tokens=128,\n",
    "            num_beams=5,\n",
    "            early_stopping=True\n",
    "        )\n",
    "        decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "        if \"<extra_id_0>\" in decoded:\n",
    "            result = decoded.split(\"<extra_id_0>\", 1)[-1].strip()\n",
    "        else:\n",
    "            result = decoded.strip()\n",
    "        result = result.lstrip(\" .>\")\n",
    "\n",
    "    # result = tokenizer.decode(output[0], skip_special_tokens=True).replace(\"<extra_id_0>\", \"\").strip()\n",
    "\n",
    "    print(f\" {idx}: {sentence}\")\n",
    "    print(f\" {idx}: {result}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0a73f471607d4cc8b66a14914c7ebb34": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10046844076b4923856f236029564a89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "214f7b7c45e84dc8916f31988e1039eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2370eb6bdaf646589f09aa75d1bf58ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "289192d1a6cd45b5a13c374ddd87984b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3db0691c2149494a954b4ed993fc9707": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c15f82108f424c15a5841b9255a623f0",
       "IPY_MODEL_fe638bb582bc4fbf8c36e2deff1a4e2d",
       "IPY_MODEL_b1dea5ee24944a9aa4dbd0cd7f39008b"
      ],
      "layout": "IPY_MODEL_f7c24c3d6b4644f8ad3d103dd9c75ce1"
     }
    },
    "42683c31707c4b5a9bb8aae95870881f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_289192d1a6cd45b5a13c374ddd87984b",
      "max": 45214,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7d23c5b6a3024ffcb2197740bdedb1a8",
      "value": 45214
     }
    },
    "51e221d6cecd49e1bf744269f05ec430": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_86df0975f00648819dde178a1864bcd6",
       "IPY_MODEL_42683c31707c4b5a9bb8aae95870881f",
       "IPY_MODEL_d497d8842a6040ed9d57f29465afad9a"
      ],
      "layout": "IPY_MODEL_e78bd0649de24106b06ff37f04942c0f"
     }
    },
    "56fffba355ab4331b62e1af32b65db2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "608b9c94c523414782b09b5284aef51f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "69b3e7d7fd3649b4986917204fb38ce3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "71be0ce8f4c641378c799fc231abe6dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7d23c5b6a3024ffcb2197740bdedb1a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "85912ace6ed1420397426adf5f44cf7b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86df0975f00648819dde178a1864bcd6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_56fffba355ab4331b62e1af32b65db2b",
      "placeholder": "",
      "style": "IPY_MODEL_10046844076b4923856f236029564a89",
      "value": "Map:100%"
     }
    },
    "908b8c7f74a34fb598a85ddb26f6e98c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1dea5ee24944a9aa4dbd0cd7f39008b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_908b8c7f74a34fb598a85ddb26f6e98c",
      "placeholder": "",
      "style": "IPY_MODEL_608b9c94c523414782b09b5284aef51f",
      "value": "180856/180856[01:48&lt;00:00,1769.55examples/s]"
     }
    },
    "c15f82108f424c15a5841b9255a623f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_214f7b7c45e84dc8916f31988e1039eb",
      "placeholder": "",
      "style": "IPY_MODEL_71be0ce8f4c641378c799fc231abe6dd",
      "value": "Map:100%"
     }
    },
    "d497d8842a6040ed9d57f29465afad9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_85912ace6ed1420397426adf5f44cf7b",
      "placeholder": "",
      "style": "IPY_MODEL_69b3e7d7fd3649b4986917204fb38ce3",
      "value": "45214/45214[00:27&lt;00:00,1587.45examples/s]"
     }
    },
    "e78bd0649de24106b06ff37f04942c0f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f7c24c3d6b4644f8ad3d103dd9c75ce1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe638bb582bc4fbf8c36e2deff1a4e2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a73f471607d4cc8b66a14914c7ebb34",
      "max": 180856,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2370eb6bdaf646589f09aa75d1bf58ec",
      "value": 180856
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
